{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas 规整\n",
    "\n",
    "* pandas.concat() 将多个数据帧在特定轴 (行、列) 方向进行拼接\n",
    "* pandas.DataFrame.drop() 删除数据帧特定列\n",
    "* pandas.DataFrame.join() 将两个数据集按照索引或指定列进行合并\n",
    "* pandas.DataFrame.merge() 按照指定的列标签或索引进行数据库风格的合并\n",
    "* pandas.DataFrame.pivot() 用于将数据透视成新的行和列形式的函数\n",
    "* pandas.DataFrame.stack() 将 DataFrame 中的列转换为多级索引的行形式的函数\n",
    "* pandas.DataFrame.unstack() 将 DataFrame 中的多级索引行转换为列形式的函数\n",
    "* pandas.melt() 将宽格式数据转换为长格式数据的函数，将多个列“融化”成一列\n",
    "* pandas.pivot_table() 根据指定的索引和列对数据进行透视，并使用聚合函数合并重复值的函数\n",
    "* pandas.wide_to_long() 将宽格式数据转换为长格式数据的函数，类似于 melt()，但可以处理多个标识符列和前缀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据帧拼接&合并\n",
    "\n",
    "将不同数据源的数据合并成一个数据集是数据规整的常见需求之一。\n",
    "Pandas 提供了多种方法进行数据合并和连接:\n",
    "比如，方法 concat() 将多个数据帧在特定轴方向进行拼接。\n",
    "方法 join() 将两个数据集按照索引或指定列进行合并。\n",
    "方法 merge() 按照指定的列标签或索引进行数据库风格的合并。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat()\n",
    "\n",
    "pandas.concat() 是 pandas 库中的一个函数，用于将多个数据结构按照行或列的方向进行合并。\n",
    "\n",
    "它可以将数据连接在一起，形成一个新的 DataFrame。\n",
    "\n",
    "这个函数的主要参数为 `pandas.concat(objs, axis=0, join='outer', ignore_index=False)`。\n",
    "\n",
    "* 参数objs: 这是一个需要连接的对象的列表，比如 [df1, df2, df3]。\n",
    "\n",
    "* 参数axis 指定连接的轴向，可以是 0 或 1，默认为0；0 表示按行连接，1 表示按列连接。\n",
    "\n",
    "* 参数join 指定拼接的方式，可以是 'inner'、'outer'，默认是 'outer'。'inner' 表示内连接，只保留两个\n",
    "数据集中共有的列/行。'outer' 表示外连接，保留所有列/行，缺失值用 NaN 填充。 \n",
    "\n",
    "* 参数ignore_index 为布尔值，默认为False；如果设置为 True，将会重新生成索引，忽略原来的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1:\n",
      "   X1 X2\n",
      "0   1  X\n",
      "1   2  Y\n",
      "2   3  Z\n",
      "df2:\n",
      "  X3  X4\n",
      "1  A   4\n",
      "2  B   5\n",
      "3  C   6\n",
      "    X1   X2   X3   X4\n",
      "0  1.0    X  NaN  NaN\n",
      "1  2.0    Y    A  4.0\n",
      "2  3.0    Z    B  5.0\n",
      "3  NaN  NaN    C  6.0\n",
      "   X1 X2 X3  X4\n",
      "1   2  Y  A   4\n",
      "2   3  Z  B   5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 创建两个数据帧\n",
    "df1 = pd.DataFrame({'X1': [1, 2, 3],\n",
    "'X2': ['X', 'Y', 'Z']},\n",
    "index=[0, 1, 2])\n",
    "df2 = pd.DataFrame({'X3': ['A', 'B', 'C'],\n",
    "'X4': [4, 5, 6]},\n",
    "index=[1, 2, 3])\n",
    "print(\"df1:\")\n",
    "print(df1)\n",
    "print(\"df2:\")\n",
    "print(df2)\n",
    "# 'outer' 方法拼接\n",
    "df_outer = pd.concat([df1, df2], join='outer', axis=1)\n",
    "print(df_outer)  # 可以看到,当 axis = 1 时,会把列拼接在一起,in/out 影响的是不同值的行标签对如何合并\n",
    "# 'inner' 方法拼接\n",
    "df_inner = pd.concat([df1, df2], join='inner', axis=1)\n",
    "print(df_inner)  # 缺失的值会填充 NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join()\n",
    "\n",
    "join 是 DataFrame 对象的一个方法，用于按照索引 (默认) 或指定列合并两个 DataFrame。\n",
    "\n",
    "主要参数为DataFrame.join(other, on = None, how = 'left', lsuffix = '', rsuffix = '')\n",
    "\n",
    "other 是要连接的另一个 DataFrame\n",
    "\n",
    "on 是指定链接的列名或列标签级别的名称. 如果不指定,将会以两个 DataFrame 的索引为连接依据.\n",
    "\n",
    "how 指定连接方式, 可以是:\n",
    "* left : 使用左侧 DataFrame 的索引或指定列进行合并\n",
    "* right : 使用右侧 DataFrame 的索引或指定列进行合并\n",
    "* outer : 使用两个 DataFrame 的并集索引或指定列进行合并,缺失值用 NaN 填充\n",
    "* inner : 使用两个 DataFrame 的交集索引或者使用指定列进行合并\n",
    "* cross : 笛卡尔积的连接方式,会将两个 DataFrame 的所有行进行组合,从而得到两个 DataFrame 之间的所欲可能组合\n",
    "一共四种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1 X2   X3   X4\n",
      "0   1  X  NaN  NaN\n",
      "1   2  Y    A  4.0\n",
      "2   3  Z    B  5.0\n",
      "    X1   X2 X3  X4\n",
      "1  2.0    Y  A   4\n",
      "2  3.0    Z  B   5\n",
      "3  NaN  NaN  C   6\n",
      "    X1   X2   X3   X4\n",
      "0  1.0    X  NaN  NaN\n",
      "1  2.0    Y    A  4.0\n",
      "2  3.0    Z    B  5.0\n",
      "3  NaN  NaN    C  6.0\n",
      "   X1 X2 X3  X4\n",
      "1   2  Y  A   4\n",
      "2   3  Z  B   5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 创建两个数据帧\n",
    "df1 = pd.DataFrame({'X1': [1,2,3],\n",
    "                    'X2': ['X', 'Y', 'Z']}, \n",
    "                    index = [0, 1, 2])\n",
    "\n",
    "df2 = pd.DataFrame({'X3': ['A', 'B', 'C'],\n",
    "                    'X4': [4, 5, 6]},\n",
    "                    index = [1, 2, 3])\n",
    "\n",
    "df_left = df1.join(df2, how='left')\n",
    "print(df_left)  # 以 df1 的索引为最终结果,不匹配的行则直接填充 NaN\n",
    "df_right = df1.join(df2, how='right')\n",
    "print(df_right)\n",
    "df_outer = df1.join(df2, how='outer')\n",
    "print(df_outer)\n",
    "df_inner = df1.join(df2, how='inner')  \n",
    "print(df_inner) # 只会输出二者都有的行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dddf1 = pd.DataFrame({'X1': [1,2,3],\n",
    "                    'X2': ['X', 'Y', 'Z']}, \n",
    "                    index = [0, 1, 2])\n",
    "\n",
    "dddf2 = pd.DataFrame({'X2': ['A', 'B', 'C'],\n",
    "                    'X4': [4, 5, 6]},\n",
    "                    index = [1, 2, 3])\n",
    "\n",
    "df_test = pd.merge(dddf1, dddf2, on = 'X2', how = 'outer')\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1 X2 X3  X4\n",
      "0   1  X  A   4\n",
      "1   1  X  B   5\n",
      "2   1  X  C   6\n",
      "3   2  Y  A   4\n",
      "4   2  Y  B   5\n",
      "5   2  Y  C   6\n",
      "6   3  Z  A   4\n",
      "7   3  Z  B   5\n",
      "8   3  Z  C   6\n"
     ]
    }
   ],
   "source": [
    "df_test = df1.join(df2, how='cross') \n",
    "print(df_test) # cross 就是将两个 dataframe 的列作笛卡尔积,列则是新生成的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  D\n",
      "0  1  X  4\n",
      "1  2  Y  5\n",
      "2  3  Z  6\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "在这个示例中，df1和df2有不同的列名。我们希望根据列'B'和列'C'的匹配进行合并。\n",
    "通过使用on='B'参数，我们指定了根据'B'列进行合并。\n",
    "'''\n",
    "\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3],\n",
    "                    'B': ['X', 'Y', 'Z']})\n",
    "\n",
    "df2 = pd.DataFrame({'C': ['X', 'Y', 'Z'],\n",
    "                    'D': [4, 5, 6]})\n",
    "\n",
    "df = df1.join(df2.set_index('C'), on='B')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge()\n",
    "\n",
    "merge 比起前面两种方法,还要更灵活\n",
    "\n",
    "merge() 可以通过指定列标签合并 (参数left_on 和 right_on，或on)，可以指定索引 (left_index 和 right_index) 合并。\n",
    "\n",
    "merge() 还支持'left'、'right'、'outer'、'inner' 或 'cross'五种合并方法。\n",
    "\n",
    "#### 基于单个列合并\n",
    "\n",
    "**注意,当两个数据帧有同名列标签时,合并后同名标签会加后缀以便区分,默认为 _x 和 _y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X1 X2   X4\n",
      "0  1.0  X  NaN\n",
      "1  2.0  Y  NaN\n",
      "2  3.0  Z  NaN\n",
      "3  NaN  A  4.0\n",
      "4  NaN  B  5.0\n",
      "5  NaN  C  6.0\n",
      "   X1 X2  X4\n",
      "0   1  X NaN\n",
      "1   2  Y NaN\n",
      "2   3  Z NaN\n"
     ]
    }
   ],
   "source": [
    "dddf1 = pd.DataFrame({'X1': [1,2,3],\n",
    "                    'X2': ['X', 'Y', 'Z']}, \n",
    "                    index = [0, 1, 2])\n",
    "\n",
    "dddf2 = pd.DataFrame({'X2': ['A', 'B', 'C'],\n",
    "                    'X4': [4, 5, 6]},\n",
    "                    index = [1, 2, 3])\n",
    "\n",
    "df_test = pd.merge(dddf1, dddf2, on = 'X2', how = 'outer') # merge 是将两个合并的放在第一 / 第二个参数\n",
    "print(df_test) # on 指的是二者的共同列名\n",
    "\n",
    "# 其实也可以对 DataFrame 对象调用 merge 函数,笑死\n",
    "\n",
    "df_test = dddf1.merge(dddf2, how = 'left')\n",
    "print(df_test)  # 当不指定 on 的时候,也是默认行标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于左右列合并\n",
    "\n",
    "merge 函数可以通过参数分别指定左边和右边用于比较的列标签名\n",
    "\n",
    "两个参数分别是 left_on 和 right_on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   M  X    Y    N\n",
      "0  1  A  NaN  NaN\n",
      "1  2  B    B  4.0\n",
      "2  3  C    C  5.0\n",
      "   M  X  Y  N\n",
      "0  2  B  B  4\n",
      "1  3  C  C  5\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'M': [1,2,3],\n",
    "                    'X': ['A', 'B', 'C']}, \n",
    "                    index = [0, 1, 2])\n",
    "\n",
    "df2 = pd.DataFrame({'Y': ['B', 'C', 'D'],\n",
    "                    'N': [4, 5, 6]},\n",
    "                    index = [1, 2, 3])\n",
    "\n",
    "left_df = pd.merge(df1, df2, how = 'left', left_on='X', right_on='Y')\n",
    "print(left_df)  # 按照 左边的 X 和 右边的 Y 的值一起匹配. 不过可以看到这两个匹配的列还是会在,不会合并.\n",
    "\n",
    "inner_df = pd.merge(df1, df2, how = 'inner', left_on='X', right_on='Y')\n",
    "print(inner_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 独有\n",
    "\n",
    "合并几何运算一共有 8 种,除了前面提到的五种,还有三种:\n",
    "1. left exclusive: 只保留左侧 DataFrame 中存在,而右侧 Dataframe 中不存在的行.(即相交的也不会输出来)\n",
    "2. right exclusive: 只保留右侧 DataFrame 中存在,而左侧 DataFrame 种不存在的行."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before filter & drop, left_exl:\n",
      "    M  X     N     _merge\n",
      "0  1  a   NaN  left_only\n",
      "1  2  b  22.0       both\n",
      "2  3  c  33.0       both\n",
      "left_exl\n",
      "    M  X   N\n",
      "0  1  a NaN\n",
      "right_exl\n",
      "     M  X   N\n",
      "2 NaN  d  44\n"
     ]
    }
   ],
   "source": [
    "# 创建两个数据帧\n",
    "left_data = {\n",
    "    'M': [ 1, 2, 3],\n",
    "    'X': ['a', 'b', 'c']}\n",
    "left_df = pd.DataFrame(left_data)\n",
    "\n",
    "right_data = {\n",
    "    'X': ['b', 'c', 'd'],\n",
    "    'N': [ 22, 33, 44]}\n",
    "right_df = pd.DataFrame(right_data)\n",
    "\n",
    "# LEFT EXCLUSIVE\n",
    "left_exl = left_df.merge(right_df, on='X', how='left', indicator=True)\n",
    "print('before filter & drop, left_exl:\\n', left_exl)\n",
    "# merge() 方法中，indicator 参数用于指定是否添加一个特殊的列，该列记录了每行的合并方式。\n",
    "# 这个特殊的列名可以通过 indicator 参数进行定义,默认为 \"_merge\".\n",
    "# 列里的值有三种: left_only, right_only, both\n",
    "# 分别代表左边独有, 右边独有, 共有\n",
    "left_exl = left_exl[left_exl['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "print('left_exl\\n',left_exl )\n",
    "\n",
    "# RIGHT EXCLUSIVE\n",
    "right_exl = left_df.merge(right_df, on='X', how='right', indicator=True)\n",
    "right_exl = right_exl[right_exl['_merge'] == 'right_only'].drop(columns=['_merge'])\n",
    "print('right_exl\\n', right_exl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据帧的重塑和透视\n",
    "\n",
    "数据帧的重塑和透视操作是指通过重新组织数据的方式，使数据呈现出不同的结构，以满足特定的分析需求.\n",
    "\n",
    "数据帧重塑 (reshaping) 是指改变数据的行和列的排列方式.\n",
    "\n",
    "数据帧透视 (pivoting) 是指通过旋转数据的行和列，以重新排列数据，并根据指定的聚合函数来生成新的数据帧。一般这样操作是为了更好地展示数据的结构和统计特征.\n",
    "\n",
    "长格式、宽格式是本章重要概念。长格式 (long format) 和宽格式 (wide format) 是两种不同的数据存储形式。\n",
    "\n",
    "长格式类似流水账，每一行代表一个观察值，比如某个学生某科目期中考试成绩。\n",
    "\n",
    "宽格式更像是“矩阵”，每一行代表一个特定观察条件，比如某个特定学生的学号。\n",
    "\n",
    "此外，宽格式数据的列用于表示不同的特征或维度，比如特定科目。显然，长格式、宽格式之间可以很容易相互转化。Pandas 提供很多方法用来完成数据帧的重塑和透视。\n",
    "\n",
    "接下来要介绍的三种操作分别是:\n",
    "1. pivot() 函数,用于根据一个或多个列创建一个新的数据透视表. pivot_table() 与 pivot() 类似,它也可以执行透视操作,但允许对重复的索引值进行聚合,产生一个透视表.它对处理有重复数据的情况更加适用.\n",
    "2. stack() 函数用于将数据帧从宽格式转换为长格式. melt() 函数也可用于将数据从宽格式转换为长格式.\n",
    "3. unstack() 是 stack() 的逆操作,用于将数据从长格式转换为宽格式."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pivot() 长格式转换为宽格式\n",
    "\n",
    "pivot() 可以理解为一种长格式转换为宽格式的特殊情况。\n",
    "\n",
    "pivot()需要指定三个参数：index，columns 和 values，它们分别代表新DataFrame 的行索引、列索引和填充数据的值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "   Student ID  Subject  Midterm  Final\n",
      "0          1     Math        4      3\n",
      "1          1      Art        5      4\n",
      "2          2  Science        3      5\n",
      "3          2      Art        5      3\n",
      "4          3     Math        4      4\n",
      "5          3  Science        5      4\n",
      "6          4      Art        3      4\n",
      "7          4     Math        5      5\n",
      "after pivot:\n",
      " Subject     Art  Math  Science\n",
      "Student ID                    \n",
      "1           5.0   4.0      NaN\n",
      "2           5.0   NaN      3.0\n",
      "3           NaN   4.0      5.0\n",
      "4           3.0   5.0      NaN\n",
      "two values pivot:\n",
      "            Midterm              Final             \n",
      "Subject        Art Math Science   Art Math Science\n",
      "Student ID                                        \n",
      "1              5.0  4.0     NaN   4.0  3.0     NaN\n",
      "2              5.0  NaN     3.0   3.0  NaN     5.0\n",
      "3              NaN  4.0     5.0   NaN  4.0     4.0\n",
      "4              3.0  5.0     NaN   4.0  5.0     NaN\n"
     ]
    }
   ],
   "source": [
    "# pivot() \n",
    "data = {'Student ID':['1','1','2','2','3','3','4','4'],\n",
    "        'Subject': ['Math','Art','Science','Art',\n",
    "                    'Math','Science', 'Art','Math'],\n",
    "                    'Midterm': [4, 5, 3, 5, 4, 5, 3, 5],\n",
    "                    'Final': [3, 4, 5, 3, 4, 4, 4, 5]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"data:\\n\", df)\n",
    "\n",
    "pivot_df = df.pivot(index= 'Student ID', columns='Subject', values= 'Midterm')\n",
    "print('after pivot:\\n', pivot_df)  # 没有 match 的值会自动填充 NaN\n",
    "\n",
    "pivot_df_2 = df.pivot(index= 'Student ID', columns='Subject' , values=['Midterm', 'Final'])\n",
    "print(\"two values pivot:\\n\", pivot_df_2)  # 当 values 为列表时,会生成双重列标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pivot_tabel:\n",
      "                     Final  Midterm\n",
      "Subject Student ID                \n",
      "Art     1               4        5\n",
      "        2               3        5\n",
      "        4               4        3\n",
      "Math    1               3        4\n",
      "        3               4        4\n",
      "        4               5        5\n",
      "Science 2               5        3\n",
      "        3               4        5\n"
     ]
    }
   ],
   "source": [
    "# pivot_table 可以完成上面一样的操作: df.pivot_table(index='Student ID', columns = 'Subject', values='Midterm')\n",
    "# 和pivot() 不同的是，pivot_table() 可以不用指定columns\n",
    "# pivot_table() 可以把数据帧里的学号 & 科目转化成双层行索引\n",
    "\n",
    "pivot_t_df = df.pivot_table(index=['Subject', 'Student ID'],values=['Midterm','Final'])\n",
    "print(\"pivot_tabel:\\n\" , pivot_t_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stack() 宽格式转换成长格式\n",
    "\n",
    "stack() 是一种将列逐级转换为层次化索引的操作。\n",
    "\n",
    "如果DataFrame 的列是层次化索引，那么stack()会将最内层的列转换为最内层的索引。该函数返回一个Series 或DataFrame，具体取决于原始数据的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Art  Math  Science\n",
      "1    3     4        3\n",
      "2    4     4        5\n",
      "3    3     5        3\n",
      "4    3     3        5\n",
      "\n",
      "after change names,df:\n",
      " Subject     Art  Math  Science\n",
      "Student ID                    \n",
      "1             3     4        3\n",
      "2             4     4        5\n",
      "3             3     5        3\n",
      "4             3     3        5\n",
      "\n",
      "after reset_index, df:\n",
      " Subject  Student ID  Art  Math  Science\n",
      "0                 1    3     4        3\n",
      "1                 2    4     4        5\n",
      "2                 3    3     5        3\n",
      "3                 4    3     3        5\n",
      "\n",
      "after stack , df:\n",
      " Student ID  Subject\n",
      "1           Art        3\n",
      "            Math       4\n",
      "            Science    3\n",
      "2           Art        4\n",
      "            Math       4\n",
      "            Science    5\n",
      "3           Art        3\n",
      "            Math       5\n",
      "            Science    3\n",
      "4           Art        3\n",
      "            Math       3\n",
      "            Science    5\n",
      "dtype: int64\n",
      "\n",
      "after stack & reset_index, df:\n",
      "     Student ID  Subject  0\n",
      "0            1      Art  3\n",
      "1            1     Math  4\n",
      "2            1  Science  3\n",
      "3            2      Art  4\n",
      "4            2     Math  4\n",
      "5            2  Science  5\n",
      "6            3      Art  3\n",
      "7            3     Math  5\n",
      "8            3  Science  3\n",
      "9            4      Art  3\n",
      "10           4     Math  3\n",
      "11           4  Science  5\n",
      "\n",
      " Subject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "student_ids = [1, 2, 3, 4]\n",
    "subjects = ['Art', 'Math', 'Science']\n",
    "np.random.seed(0)\n",
    "# 使用随机数生成成绩数据\n",
    "scores = np.random.randint(3, 6,size=(len(student_ids),len(subjects)))\n",
    "# 创建数据帧\n",
    "df = pd.DataFrame(scores, index=student_ids, columns=subjects)\n",
    "print(df)\n",
    "\n",
    "# 修改行列名称\n",
    "df.columns.names = ['Subject'] # colums 有两个属性,一个是 name, 一个是 names. 前者是各列的名字,后者是列名的名字\n",
    "df.index.names = ['Student ID']\n",
    "print(\"\\nafter change names,df:\\n\" , df)\n",
    "\n",
    "\n",
    "reset_df = df.reset_index() # reset_index() 方法可以将行索引转换为列索引\n",
    "print('\\nafter reset_index, df:\\n', reset_df)\n",
    "\n",
    "# 将长格式转换为宽格式\n",
    "stack_df = df.stack()#.reset_index() # .rename(columns={0: 'Final'})\n",
    "print(\"\\nafter stack , df:\\n\", stack_df) # stack() 方法可以将数据帧的列转换为行,也可以看成是将列索引转换为行索引\n",
    "stack_df = stack_df.reset_index()\n",
    "print(\"\\nafter stack & reset_index, df:\\n\", stack_df) # reset_index() 方法可以将行索引转换为列索引\n",
    "\n",
    "print(\"\\n\", df.columns.name)\n",
    "\n",
    "\n",
    "# 结合前面的信息来看,如果 reset_index 前 columns 有 names, 那么 reset_index 之后的列名就会是 names 的值\n",
    "# 如果 reset_index 前 columns 没有 names, 那么 reset_index 之后的列名就会是 name 的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Group 1           Group 2  A  B\n",
      "  Column 1 Column 2 Column 3      \n",
      "0      NaN      NaN      NaN  1  4\n",
      "1      NaN      NaN      NaN  2  5\n",
      "2      NaN      NaN      NaN  3  6\n",
      "\n",
      "\n",
      "[None, None]\n",
      "\n",
      "\n",
      "['Group', 'Column']\n",
      "\n",
      " Group   Group 1           Group 2  A  B\n",
      "Column Column 1 Column 2 Column 3      \n",
      "0           NaN      NaN      NaN  1  4\n",
      "1           NaN      NaN      NaN  2  5\n",
      "2           NaN      NaN      NaN  3  6\n",
      "\n",
      " after stack, ddf:\n",
      " Group    Group 1 Group 2    A    B\n",
      "  Column                          \n",
      "0            NaN     NaN  1.0  4.0\n",
      "1            NaN     NaN  2.0  5.0\n",
      "2            NaN     NaN  3.0  6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "ddf = pd.DataFrame(data, columns=[['Group 1', 'Group 1', 'Group 2'], ['Column 1', 'Column 2', 'Column 3']])\n",
    "ddf['A'] = [1,2,3]\n",
    "ddf['B'] = [4,5,6]\n",
    "print(ddf)\n",
    "print(\"\\n\")\n",
    "print(ddf.columns.names)  # 获取多级列索引的层级名称\n",
    "print(\"\\n\")\n",
    "\n",
    "ddf.columns.names = ['Group', 'Column']  # 设置多级列索引的层级名称,也可以从输出中看出,\n",
    "                                         # Group 是第一层级的列名, Column 是第二层级的列名\n",
    "print(ddf.columns.names )\n",
    "print(\"\\n\", ddf)\n",
    "\n",
    "stack_ddf = ddf.stack()  # 将列索引转换为行索引\n",
    "print(\"\\n after stack, ddf:\\n\", stack_ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "melt() 将原始数据中的多列合并为一列，并根据其他列的值对新列进行重复。可以理解为stack() 的一种泛化形式。\n",
    "\n",
    "melt() 需要指定id_vars 参数，表示保持不变的列，同时还可以选择value_vars 参数来指定哪些列需要被转换。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
